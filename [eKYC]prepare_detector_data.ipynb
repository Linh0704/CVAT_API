{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import uuid\n",
    "import logging\n",
    "import getpass\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import imageio\n",
    "import random\n",
    "import shutil\n",
    "import copy\n",
    "import glob\n",
    "import json\n",
    "import shutil\n",
    "import pickle\n",
    "import traceback\n",
    "import zipfile\n",
    "from collections import Counter\n",
    "from pprint import pprint as print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from PIL import Image, ImageDraw, ExifTags\n",
    "from shapely.geometry import Polygon\n",
    "import imgaug\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "import skimage\n",
    "from skimage import io, color\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, figsize=(16, 16)):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    ax.axis('off')\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_api import CLI, CVAT_API_V1, ResourceType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    \n",
    "    def __init__(self, action=\"create\"):\n",
    "        \n",
    "        self.action = action\n",
    "        self.auth = (\"\", \"\")  # type tuple\n",
    "        self.server_host = \"\"\n",
    "        self.server_port = 8080\n",
    "        self.https = False\n",
    "        self.loglevel = 20\n",
    "\n",
    "        self.name = \"test\"\n",
    "        self.labels = [{\"name\":\"text\", \"attributes\": []}]  # type list\n",
    "        self.overlap = 0\n",
    "        self.segment_size = 0\n",
    "        self.bug = \"\"\n",
    "        self.resource_type = ResourceType(0)\n",
    "        self.resources = [\"/home/phan.huy.hoang/Pictures/test_img_cvat.zip\"]\n",
    "        self.annotation_path = \"/home/phan.huy.hoang/cvat/utils/cli/instances_default.json\"\n",
    "        self.annotation_format = \"COCO 1.0\"\n",
    "\n",
    "        # for git only\n",
    "        self.completion_verification_period = 10\n",
    "        self.dataset_repository_url = \"\"\n",
    "        self.lfs = False\n",
    "\n",
    "args = Args()\n",
    "CVAT_URL = \"http://{}:{}/\".format(args.server_host, args.server_port)\n",
    "API_URL = CVAT_URL + \"api/v1/\"\n",
    "username, password = args.auth\n",
    "username, password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cookies():\n",
    "    login_json = {\"username\": username, \"password\": password}\n",
    "    login_req = requests.post(API_URL + 'auth/login', json=login_json)\n",
    "    cookies = login_req.cookies\n",
    "    return cookies\n",
    "\n",
    "cookies = get_cookies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(\"{}/api/v1/tasks/1043\".format(CVAT_URL), cookies=cookies)\n",
    "req.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ids = list(range(1043, 1047)) + list(range(1048, 1063))  # ignore task 1047\n",
    "print(len(task_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download cả ảnh + label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_dir = \"/media/SUN-ASTERISK\\phan.huy.hoang/My Passport/phanhoang/data/CMT_CCCD/CVAT/downloaded_cropper/zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_fmt = \"http://{}:8080/api/v1/tasks/{}/dataset?format=COCO%201.0&action=download\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(req, task_id):\n",
    "    with open(os.path.join(saved_dir, '{}.zip'.format(task_id)), 'wb') as f:\n",
    "        for chunk in req.iter_content(chunk_size=1024): \n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "    print(\"Task {}: download completed\".format(task_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_id in tqdm_notebook(task_ids):\n",
    "    url = url_fmt.format(args.server_host, task_id)\n",
    "\n",
    "    while True:\n",
    "        req = requests.get(url, cookies=cookies)\n",
    "        if req.status_code == 200:\n",
    "            download_file(req, task_id)\n",
    "            break\n",
    "\n",
    "    time.sleep(10)\n",
    "    \n",
    "# unzip all zip files in the same root folder\n",
    "for task_id in task_ids:\n",
    "    zip_fp = os.path.join(saved_dir, \"{}.zip\".format(task_id))\n",
    "    assert os.path.exists(zip_fp)\n",
    "    \n",
    "    task_dir = os.path.join(saved_dir, str(task_id))\n",
    "    if not os.path.exists(task_dir):\n",
    "        os.mkdir(task_dir)\n",
    "        \n",
    "    with zipfile.ZipFile(zip_fp, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(task_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cắt ảnh theo perspective transform (4 góc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_point(c):\n",
    "    x, y, w, h = c\n",
    "    x_center = int(x + w / 2)\n",
    "    y_center = int(y + h / 2)\n",
    "    return x_center, y_center\n",
    "\n",
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    # return the ordered coordinates\n",
    "    return rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    # obtain a consistent order of the points and unpack them\n",
    "    # individually\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "    # compute the width of the new image, which will be the\n",
    "    # maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "    # compute the height of the new image, which will be the\n",
    "    # maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    # now that we have the dimensions of the new image, construct\n",
    "    # the set of destination points to obtain a \"birds eye view\",\n",
    "    # (i.e. top-down view) of the image, again specifying points\n",
    "    # in the top-left, top-right, bottom-right, and bottom-left\n",
    "    # order\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype = \"float32\")\n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "    # return the warped image\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_content(fd):\n",
    "    shutil.rmtree(fd)\n",
    "    os.mkdir(fd)\n",
    "\n",
    "# remove_all_content(warped_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_existed_or_create(fd):\n",
    "    if not os.path.exists(fd):\n",
    "        os.mkdir(fd)\n",
    "        \n",
    "for type_idcard in [\"cmnd\", \"cccd\", \"cccd_chip\"]:\n",
    "    first_dir = os.path.join(warped_dir, type_idcard)\n",
    "    check_existed_or_create(first_dir)\n",
    "    for mode in [\"front\", \"back\"]:\n",
    "        second_dir = os.path.join(first_dir, mode)\n",
    "        check_existed_or_create(second_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_dir = \"/media/SUN-ASTERISK\\phan.huy.hoang/My Passport/phanhoang/data/CMT_CCCD/CVAT/downloaded_cropper/warped\"\n",
    "assert os.path.exists(warped_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_fps = []\n",
    "\n",
    "def process_task(anno_fp, img_dir):\n",
    "    # for 1 task\n",
    "    with open(anno_fp, \"r\") as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    json_df = pd.DataFrame(json_data[\"annotations\"])\n",
    "    json_df = pd.concat([json_df.drop(['attributes'], axis=1), json_df['attributes'].apply(pd.Series)], axis=1)\n",
    "    \n",
    "    label_mapping = dict()\n",
    "    for d in json_data[\"categories\"]:\n",
    "        label_mapping[d[\"name\"]] = d[\"id\"]\n",
    "    \n",
    "    for img_index, img_info in enumerate(tqdm_notebook(json_data[\"images\"])):\n",
    "        img_id = img_info[\"id\"]\n",
    "        img_fn = img_info[\"file_name\"]\n",
    "        img_fp = os.path.join(img_dir, img_fn)\n",
    "\n",
    "        try:\n",
    "            img_df = json_df[json_df[\"image_id\"].isin([img_id])]\n",
    "            pil_img = Image.open(img_fp)\n",
    "            pil_img = pil_img.convert('RGB')\n",
    "            img = np.array(pil_img)\n",
    "\n",
    "            if len(img_df) == 4:\n",
    "                is_front = False\n",
    "            else:\n",
    "                is_front = True\n",
    "            # check nb rows == 4 or 5 (4/5 classes)\n",
    "            # check 4 or 5 unique category ids (ignore wrong annotation)\n",
    "            # idcard's type it not np.nan (annotated in top-left object)\n",
    "            try:\n",
    "                assert len(img_df) in [4, 5]\n",
    "                if is_front:\n",
    "                    assert len(img_df[\"category_id\"].unique()) == 5\n",
    "                else:\n",
    "                    assert len(img_df[\"category_id\"].unique()) == 4\n",
    "                assert img_df[img_df[\"category_id\"] == 1][\"type\"].values[0] is not np.nan\n",
    "            except Exception:\n",
    "    #             print(\"Error: {}\".format(img_fp))\n",
    "                error_fps.append(img_fp)\n",
    "                continue\n",
    "\n",
    "            is_valid = True\n",
    "            for row_index, row in img_df.iterrows():\n",
    "                c_id = row[\"category_id\"]\n",
    "                bbox = copy.deepcopy(row[\"bbox\"])\n",
    "                if c_id == label_mapping[\"top_left\"]:\n",
    "                    tl = bbox\n",
    "                    type_idcard = row[\"type\"]\n",
    "                    if type_idcard is np.nan:\n",
    "                        is_valid = False\n",
    "                        break\n",
    "                elif c_id == label_mapping[\"top_right\"]:\n",
    "                    tr = bbox\n",
    "                elif c_id == label_mapping[\"bottom_left\"]:\n",
    "                    bl = bbox\n",
    "                elif c_id == label_mapping[\"bottom_right\"]:\n",
    "                    br = bbox\n",
    "            if not is_valid:\n",
    "                continue\n",
    "\n",
    "            if type_idcard not in [\"cmnd\", \"cccd\", \"cccd_chip\"]:\n",
    "                error_fps.append(img_fp)\n",
    "                continue\n",
    "\n",
    "            pts = np.array([\n",
    "                get_center_point(tl),\n",
    "                get_center_point(tr),\n",
    "                get_center_point(br),\n",
    "                get_center_point(bl)\n",
    "            ])\n",
    "            pts = order_points(pts)\n",
    "            warped_img = four_point_transform(img, pts)\n",
    "\n",
    "            if is_front:\n",
    "                sub_dir = \"front\"\n",
    "            else:\n",
    "                sub_dir = \"back\"\n",
    "            warped_img_fp = os.path.join(warped_dir, type_idcard, sub_dir, \"warped_{}\".format(img_fn))\n",
    "\n",
    "            # rotate image\n",
    "            h, w, _ = warped_img.shape\n",
    "            if h > w:\n",
    "                # check rotated 90 degree image\n",
    "                x1, y1 = get_center_point(tl)\n",
    "                x3, y3 = get_center_point(br)\n",
    "                if x1 > x3:\n",
    "                    # rotate -90 degree\n",
    "                    warped_img = cv2.rotate(warped_img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "                else:\n",
    "                    # rotate 90 degree\n",
    "                    warped_img = cv2.rotate(warped_img, cv2.ROTATE_90_CLOCKWISE)\n",
    "            else:\n",
    "                # check reverse image\n",
    "                y_center_top = (get_center_point(tl)[1] + get_center_point(tr)[1]) / 2 \n",
    "                y_center_bottom = (get_center_point(bl)[1] + get_center_point(br)[1]) / 2 \n",
    "                if y_center_top > y_center_bottom:\n",
    "                    warped_img = cv2.rotate(warped_img, cv2.ROTATE_180)\n",
    "\n",
    "            del tl, tr, br, bl\n",
    "        #     print(\"{} - {}\".format(img_fn, is_convert_rgb))\n",
    "#             print(\"{} - {}\".format(img.shape, warped_img.shape))\n",
    "            imageio.imwrite(warped_img_fp, warped_img)\n",
    "        except Exception:\n",
    "            error_fps.append(img_fp)\n",
    "            traceback.print_exc()\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_id in tqdm_notebook(task_ids):\n",
    "    task_dir = os.path.join(saved_dir, str(task_id))\n",
    "    img_dir = os.path.join(task_dir, \"images\")\n",
    "    anno_fp = os.path.join(task_dir, \"annotations\", \"instances_default.json\")\n",
    "    assert os.path.exists(task_dir)\n",
    "    assert os.path.exists(anno_fp)\n",
    "    assert os.path.exists(img_dir)\n",
    "    \n",
    "    process_task(anno_fp, img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(error_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hoangph36_env",
   "language": "python",
   "name": "hoangph36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
